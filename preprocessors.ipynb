{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessors\n",
    "\n",
    "#### Contains :\n",
    "* converting string or any kind of time objects to pandas datetime timestamp\n",
    "* Converting pandas datetime to epoch timestamps\n",
    "* normalising and standardising\n",
    "* Stationarising the timeseries\n",
    "* Differencing the time series\n",
    "* Splitting into train and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import writefile_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%writefile_run preprocessors.py \n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from sklearn.preprocessing import MinMaxScaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%writefile_run preprocessors.py -a\n",
    "\n",
    "\n",
    "def ts_to_unix(t):\n",
    "    '''\n",
    "    Converts datetime to epoch timestamps\n",
    "    Arguments:\n",
    "    single datetime object\n",
    "    '''\n",
    "    return int((t - dt.datetime(1970, 1, 1)).total_seconds()*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%writefile_run preprocessors.py -a\n",
    "\n",
    "\n",
    "def normalise_standardise(data):    \n",
    "    # Create a minimum and maximum processor object\n",
    "    min_max_scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "    # Create an object to transform the data to fit minmax processor\n",
    "#     if(window_size is None):\n",
    "    data_norm = min_max_scaler.fit_transform(data)\n",
    "#     else:\n",
    "#         # Train the min_max_scaler with training data and smooth data\n",
    "        \n",
    "#         for di in range(0,len(data),window_size):\n",
    "#             min_max_scaler.fit(data[di:di+window_size,:])\n",
    "#             data[di:di+window_size,:] = min_max_scaler.transform(data[di:di+window_size,:])\n",
    "\n",
    "#         # You normalize the last bit of remaining data\n",
    "#         min_max_scaler.fit(data[di+window_size:,:])\n",
    "#         data[di+window_size:,:] = min_max_scaler.transform(data[di+window_size:,:])\n",
    "\n",
    "#     data_standardised = (data_norm - np.mean(data_norm,axis=0)/np.std(data_norm,axis=0))\n",
    "    return data_norm,min_max_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%writefile_run preprocessors.py -a\n",
    "\n",
    "\n",
    "def split_the_data(data,test_frac=0.1):\n",
    "    '''\n",
    "    Splitting the data into train and test with default ratio = 0.1\n",
    "    Splits the data in orderly manner not random\n",
    "    '''\n",
    "    train_data = data[0:int(np.ceil((1-test_frac)*data.shape[0])),:]\n",
    "    test_data = data[-int(np.ceil(test_frac*data.shape[0])):]\n",
    "    return train_data,test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%writefile_run preprocessors.py -a\n",
    "\n",
    "\n",
    "def stationarize(data):\n",
    "    '''\n",
    "    Stationarises the data\n",
    "    '''\n",
    "    s,t = fit_seasons(data)\n",
    "\n",
    "    if(s is not None):\n",
    "        adj_sea = adjust_seasons(data,seasons=s)\n",
    "        res_data = adj_sea-(data-detrend(data))\n",
    "    else:\n",
    "        res_data = detrend(data)\n",
    "        \n",
    "    return res_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%writefile_run preprocessors.py -a\n",
    "\n",
    "\n",
    "def differencing(data,n=1,axis=-1):\n",
    "    '''\n",
    "    Does differencing on the data and order of differentiation as parameter\n",
    "    By default n=1 and axis =-1\n",
    "    '''\n",
    "    return np.diff(data,n=n,axis=axis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
